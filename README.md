# GNC-to-the-Moon-RL-Training

Project for Cloud Computing Class Spring 2025, GSU.

This project implements a distributed Reinforcement Learning (RL) training strategy on Azure, focusing on training a Soft Actor-Critic (SAC) agent using the Stable-Baselines3 library on the LunarLander environment. The goal is to leverage cloud resources for parallel training runs.

## Azure RL Training Deployment Strategy

This project provides a strategy and code for deploying and running distributed Reinforcement Learning (RL) training jobs on multiple Azure Virtual Machines (VMs).

## Features

* **Multi-VM Deployment:** Deploy a cluster of VMs using an Azure Resource Manager (ARM) template.
* **Centralized Code Distribution:** Upload project code to Azure Blob Storage. VMs automatically download the code during setup.
* **Automated VM Setup:** A custom shell script configures the environment, installs dependencies (including `jq`), and initiates training on each VM.
* **Parameterization:** Training parameters (timesteps, learning rate, buffer size, unique seed per VM) are defined in a local JSON file (`azure_vm_config.json`) and read by the setup script on each VM.
* **Centralized Results Collection:** Training logs, models, and evaluation results are uploaded back to Azure Blob Storage.
* **Managed Identity Authentication:** Uses Azure System-Assigned Managed Identities for secure access to Blob Storage from VMs without managing secrets.
* **Automated RBAC Assignment:** The deployment script automatically assigns the necessary Azure role (Storage Blob Data Contributor) to the VM identities on the storage account.

## Prerequisites

* An Azure account and subscription with sufficient quota for VMs.
* [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli) installed and logged in (`az login`).
* Python 3.x installed.
* Python `venv` module (usually included with Python 3.3+).
* Permissions to create resources in your Azure subscription (Resource Group, VMs, Storage Account, RBAC Assignments).

## Project Structure

* `deploy_rl_training.py`: The main Python script to orchestrate the entire deployment process (config, upload, ARM deploy, RBAC).
* `cloud_train.py`: The Python script executed on Azure VMs for training the RL agent.
* `setup_vm.sh`: Shell script executed by the ARM template's Custom Script Extension to set up the VM environment and run `cloud_train.py`.
* `azure_deployment.json`: Azure Resource Manager (ARM) template defining the Azure infrastructure.
* `requirements.txt`: Lists Python dependencies required for the `deploy_rl_training.py` and `cloud_train.py` scripts.
* `azure_vm_config.json`: JSON file generated by `deploy_rl_training.py` defining VM-specific training parameters (uploaded and used by `setup_vm.sh`).
* `local_train.py` (Optional): Script for local testing/training.
* `infer_model.py` (Optional): Script for loading a trained model and running inference.

## Deployment

The `deploy_rl_training.py` script handles the entire deployment workflow from your local machine.

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd <your-project-directory>
    ```

2.  **Create and activate a Python virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install Python dependencies:**
    Ensure `requirements.txt` includes packages like `gymnasium`, `stable-baselines3`, `azure-storage-blob`, `azure-identity`, `numpy`. The `deploy_rl_training.py` script requires `azure-cli`'s commands, ensure `azure-cli` is installed globally or accessible in your environment where you run the script. The `setup_vm.sh` script ensures `jq` is installed on the VMs.
    ```bash
    pip install -r requirements.txt
    # Ensure az cli is installed globally or accessible
    ```

4.  **Run the deployment script:**
    Execute the `deploy_rl_training.py` script providing the necessary parameters. This script will:
    * Set the `AZURE_STORAGE_ACCOUNT` environment variable for its execution.
    * Generate `azure_vm_config.json`.
    * Upload all necessary code and configuration files to your designated storage account container.
    * Create the Azure Resource Group (if it doesn't exist) and deploy the infrastructure defined in `azure_deployment.json`.
    * Wait for the VMs to be created.
    * Automatically assign the "Storage Blob Data Contributor" role to each VM's Managed Identity on your storage account.
    * The Custom Script Extension on the VMs will then download `setup_vm.sh` and start the training process.

    ```bash
    python deploy_rl_training.py \
      --resource-group <your-resource-group-name> \
      --location <azure-region> \
      --storage-account <your-storage-account-name> \
      --vm-count <number-of-vms> \
      --vm-size <azure-vm-size> \
      --admin-username "<admin-username>" \
      --admin-password-or-key "<admin-password-or-ssh-public-key>" \
      --auth-type "<password-or-sshPublicKey>" \
      --code-container "rl-training-files" \
      --results-container "rl-training-results"

    # Example:
    # python deploy_rl_training.py \
    #   --resource-group my-rl-rg \
    #   --location eastus \
    #   --storage-account myrlstorage12345 \
    #   --vm-count 5 \
    #   --vm-size Standard_DS3_v2 \
    #   --admin-username azureuser \
    #   --admin-password-or-key "YourSecurePasswordOrSshPublicKeyString" \
    #   --auth-type sshPublicKey
    ```
    Make sure the `--vm-count` and `--vm-size` match your desired configuration.

    *You can use the `--skip-config`, `--skip-upload`, `--skip-deploy`, or `--skip-rbac` flags for partial runs, but typically you'll run without them for a full deployment.*

## Execution and Monitoring

* The `deploy_rl_training.py` script will print progress updates. It pauses during the ARM deployment and RBAC assignment steps.
* Once the script completes the RBAC assignment phase, the VMs' setup scripts will execute. Training will begin shortly thereafter.
* You can monitor the setup progress and training output by checking the VM's **Boot Diagnostics** in the Azure portal.
* For detailed logs or direct interaction, you can **SSH** into the VMs using the admin credentials provided during deployment. The project files will be in `$HOME/rl-project/`.
* Training artifacts (checkpoints, final model, evaluation results) are automatically uploaded to the specified results container (`rl-training-results` by default) in your Azure Storage Account. Look for directories named like `vm1_seed1000_<timestamp>/`.

## Sensitivity to Changes

The robustness of the deployment to changes depends on what you modify:

* **Training Parameters:** Changes in the default values in `cloud_train.py` are *overridden* by the values read from `azure_vm_config.json` by `setup_vm.sh`. If you want to change parameters for new runs, modify `azure_vm_config.json` (or the parameters in `deploy_rl_training.py --create-config`) and re-run the deployment.
* **CLI Argument Names:** Changing argument names in `cloud_train.py` (e.g., `--timesteps` to `--total_steps`) requires updating the `python cloud_train.py` command in `setup_vm.sh` to match.
* **Required Python Packages:** Adding dependencies to `cloud_train.py` requires updating `requirements.txt` locally and ensuring it's uploaded (handled by `deploy_rl_training.py`). Also confirm the package is installable on the target Ubuntu OS.
* **Local Artifact Paths:** If `cloud_train.py` saves files outside `$HOME/rl-project/logs/` or `$HOME/rl-project/models/`, you need to update `setup_vm.sh` (mkdir calls) and potentially `deploy_rl_training.py` (upload exclusions) and `cloud_train.py` (upload paths).
* **Blob Paths/Container Names for Results:** Changes here in `cloud_train.py` need consistency with the container names passed by `deploy_rl_training.py` and defined in `azure_deployment.json`.
* **Azure Authentication Logic:** Any changes away from Managed Identity (`DefaultAzureCredential`) requires significant changes across ARM, `setup_vm.sh`, and `cloud_train.py`.

Changes to the core RL algorithm logic within `cloud_train.py` (as long as inputs/outputs align) generally do not require changes to the deployment scripts.

## Future Improvements

* Implement automated VM shutdown or deallocation after training completes to save costs.
* Set up centralized logging or monitoring dashboards.
* Explore using Azure services specifically designed for ML/Batch processing (Azure Machine Learning, Azure Batch).
* Add input validation and more detailed error reporting in `deploy_rl_training.py`.

## License

[Specify your project license here, e.g., MIT, Apache 2.0]
