{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856654a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "SACPolicy(\n",
      "  (actor): Actor(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (latent_pi): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (mu): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (log_std): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (critic): ContinuousCritic(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (qf0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (critic_target): ContinuousCritic(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (qf0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create environment and model\n",
    "env = gym.make(\"Pendulum-v1\")  # This has a continuous action space\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "policy_network = model.policy\n",
    "q_networks = model.critic  # This contains both Q networks\n",
    "\n",
    "# Access the first and second Q networks\n",
    "q0_net = model.critic.qf0\n",
    "q2_net = model.critic_target.qf0\n",
    "print(policy_network)\n",
    "# print(q0_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6619b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_process(shared_array):\n",
    "    critic_net = shared_array[0]\n",
    "    # env = gym.make(\"Pendulum-v1\")  # This has a continuous action space\n",
    "    print(\"Critic's addr in child process\", id(critic_net))\n",
    "    # target_agent.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254a6e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/GNC_Project_Env/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/GNC_Project_Env/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'dummy_process' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "from SAC_agent_package.prime_model import prime_SAC_model\n",
    "from custom_utils import prepare_agent\n",
    "import torch.multiprocessing as tmp\n",
    "env = gym.make(\"Pendulum-v1\")  # This has a continuous action space\n",
    "tmp.set_start_method('spawn',force=True) \n",
    "\n",
    "# model = prime_SAC_model(\"MlpPolicy\", env, verbose=1)\n",
    "keyargs = {\n",
    "    'policy' : \"MlpPolicy\",\n",
    "    'env' : env,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "target_agent = prepare_agent(prime_SAC_model, keyargs)\n",
    "# model: prime_SAC_model = target_agent()\n",
    "# model.share_model_across_memory()\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\", sab=False)\n",
    "\n",
    "def dummy_process(target_agent):\n",
    "    # print(\"Critic's\",id(target_agent.critic))\n",
    "    model: prime_SAC_model = target_agent()\n",
    "    model.run_episode()\n",
    "    # print(\"Running child\")\n",
    "# print(BJA.BlackjackAgent.__init__)\n",
    "\n",
    "\n",
    "child_process = tmp.Process(target=dummy_process, kwargs={\"target_agent\": target_agent})\n",
    "\n",
    "child_process.start()\n",
    "\n",
    "child_process.join(10)\n",
    "# print(model.run_episode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b6f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.37e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 21.7      |\n",
      "|    critic_loss     | 0.213     |\n",
      "|    ent_coef        | 0.812     |\n",
      "|    ent_coef_loss   | -0.344    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "Linear trained model: Mean reward: -1548.7864421136678, Std reward: 217.21333169464916\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Mp trained model: Mean reward: -1399.514025856927, Std reward: 293.43736190188196\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create environment and model\n",
    "env = gym.make(\"Pendulum-v1\")  # This has a continuous action space\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1000)\n",
    "mean_reward , std_reward = evaluate_policy(model, env,n_eval_episodes=10)\n",
    "\n",
    "print(f\"Linear trained model: Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
    "\n",
    "mp_model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "mp_model.load(\"./output_models/test_model.zip\")\n",
    "mean_reward , std_reward = evaluate_policy(mp_model, env,n_eval_episodes=10)\n",
    "print(f\"Mp trained model: Mean reward: {mean_reward}, Std reward: {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cbfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNC_Project_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
