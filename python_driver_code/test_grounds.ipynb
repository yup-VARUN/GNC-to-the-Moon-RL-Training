{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359957fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.device('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc93c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear training model Q-key size 122\n",
      "Linear training model with 100 experiences: {'avg_reward': -0.39, 'win_rate': 0.28, 'draw_rate': 0.05, 'loss_rate': 0.67}\n",
      "MP model Q-key size 180\n",
      "MP model {'avg_reward': -0.27, 'win_rate': 0.33, 'draw_rate': 0.07, 'loss_rate': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Testing Blackjack agent by\n",
    "import gymnasium as gym\n",
    "from blackjack_agent_package import blackjack_agent_class as BJA\n",
    "from blackjack_agent_package import Q_value_table_class as QVT\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "n_episodes = 1000\n",
    "start_epsilon = 1.0\n",
    "epsilon_decay = start_epsilon / (n_episodes / 2)  # reduce the exploration over time\n",
    "final_epsilon = 0.1\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\", sab=False)\n",
    "# env = gym.wrappers.RecordEpisodeStatistics(env, buffer_length=n_episodes)\n",
    "action_size = env.action_space.n\n",
    "\n",
    "Q_value_table = QVT.QValueTable(action_size= action_size,learning_rate=learning_rate)\n",
    "agent_1 = BJA.BlackjackAgent(env, Q_value_table)\n",
    "agent_2 = BJA.BlackjackAgent(env, Q_value_table)\n",
    "\n",
    "experiences, rewards = agent_1.collect_experience(100)\n",
    "# evalution = agent_1.evaluate(100)\n",
    "\n",
    "# print(evalution)\n",
    "Q_value_table.update(experiences)\n",
    "\n",
    "# evalution = agent_2.evaluate(100)\n",
    "# print(evalution)\n",
    "evalution = agent_1.evaluate(100)\n",
    "print(\"Linear training model Q-key size\",len(Q_value_table.q_dict.keys()))\n",
    "print(\"Linear training model with 100 experiences:\",evalution)\n",
    "\n",
    "# Loading Model from multiprocess training\n",
    "Q_value_table_mp = QVT.QValueTable(action_size)\n",
    "Q_value_table_mp.load()\n",
    "\n",
    "agent_3 = BJA.BlackjackAgent(env, Q_value_table_mp)\n",
    "\n",
    "evalution = agent_3.evaluate(100)\n",
    "# \n",
    "print(\"MP model Q-key size\",len(Q_value_table_mp.q_dict.keys()))\n",
    "print(\"MP model\",evalution)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdeee18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ('exp', 'reward'), 2: ('exp', 'reward')}\n",
      "exp\n",
      "exp\n"
     ]
    }
   ],
   "source": [
    "# testing nested dict structure\n",
    "'''outputs_of_processes := dict contained as \n",
    "    #<process_id: end_results_of_episodes_of_that_process>\n",
    "        # <end_results_of_episodes_of_that_process : episode>\n",
    "            # <episode: SAR outputs ~(experience, reward), ...>\n",
    "                # episode: (experience, reward)\n",
    "# '''\n",
    "test_dict ={\n",
    "    \"PID 1\": {\n",
    "        1 :\n",
    "        (\"exp\", \"reward\"),\n",
    "        2 :\n",
    "        (\"exp\", \"reward\")\n",
    "    }\n",
    "}\n",
    "for proc_out in test_dict.values():\n",
    "    print(proc_out)\n",
    "    for episode in proc_out.values():\n",
    "        # for result in episode:\n",
    "        print(episode[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def13b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Barrier status False\n",
      "passing thru test barrier\n",
      "Passed barrier\n",
      "Test Barrier status False\n",
      "Test Barrier status False\n",
      "Waiting at barrier again\n",
      "Test Barrier status False\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as tmp\n",
    "\n",
    "test_barrier = tmp.Barrier(1)\n",
    "# def dummy_process(barrier):\n",
    "\n",
    "\n",
    "print(\"Test Barrier status\",test_barrier.broken)\n",
    "\n",
    "print(\"passing thru test barrier\")\n",
    "test_barrier.wait()\n",
    "# test_barrier.wait()\n",
    "\n",
    "print(\"Passed barrier\")\n",
    "print(\"Test Barrier status\",test_barrier.broken)\n",
    "# print(test_barrier.broken)\n",
    "\n",
    "test_barrier.reset()\n",
    "print(\"Test Barrier status\",test_barrier.broken)\n",
    "print(\"Waiting at barrier again\")\n",
    "test_barrier.wait()\n",
    "print(\"Test Barrier status\",test_barrier.broken)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c15b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/GNC_Project_Env/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/GNC_Project_Env/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'dummy_process' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import gymnasium as gym\n",
    "from blackjack_agent_package import blackjack_agent_class as BJA\n",
    "from blackjack_agent_package import Q_value_table_class as QVT\n",
    "import torch.multiprocessing as tmp\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\", sab=False)\n",
    "Q_value_table = QVT.QValueTable(action_size = env.action_space.n)\n",
    "keyword_args = {\n",
    "    \"env\" : env, \n",
    "    \"q_values\" : Q_value_table\n",
    "\n",
    "}\n",
    "\n",
    "def dummy_process(target_agent:BJA.BlackjackAgent):\n",
    "    target_agent.collect_experience()\n",
    "# print(BJA.BlackjackAgent.__init__)\n",
    "\n",
    "agent = partial(BJA.BlackjackAgent, env = env, q_values = Q_value_table)\n",
    "# agent.keywords = keyword_args\n",
    "tmp.set_start_method('spawn',force=True) \n",
    "child_process = tmp.Process(target=dummy_process, kwargs={\"target_agent\": agent})\n",
    "\n",
    "child_process.start()\n",
    "\n",
    "child_process.join(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac870135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNC_Project_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
